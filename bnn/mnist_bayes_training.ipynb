{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import figure\n",
    "from matplotlib.backends import backend_agg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "warnings.simplefilter(action='ignore')\n",
    "import seaborn as sns\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = [28, 28, 1]\n",
    "NUM_TRAIN_EXAMPLES = 60000\n",
    "NUM_HELDOUT_EXAMPLES = 10000\n",
    "NUM_CLASSES = 10\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE =128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  kl_divergence_function = (lambda q, p, _: tfd.kl_divergence(q, p) /  # pylint: disable=g-long-lambda\n",
    "                            tf.cast(NUM_TRAIN_EXAMPLES, dtype=tf.float32))\n",
    "\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tfp.layers.Convolution2DFlipout(\n",
    "          6, kernel_size=5, padding='SAME',\n",
    "          kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.relu),\n",
    "      tf.keras.layers.MaxPooling2D(\n",
    "          pool_size=[2, 2], strides=[2, 2],\n",
    "          padding='SAME'),\n",
    "      tfp.layers.Convolution2DFlipout(\n",
    "          16, kernel_size=5, padding='SAME',\n",
    "          kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.relu),\n",
    "      tf.keras.layers.MaxPooling2D(\n",
    "          pool_size=[2, 2], strides=[2, 2],\n",
    "          padding='SAME'),\n",
    "      tfp.layers.Convolution2DFlipout(\n",
    "          120, kernel_size=5, padding='SAME',\n",
    "          kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.relu),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tfp.layers.DenseFlipout(\n",
    "          84, kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.relu),\n",
    "      tfp.layers.DenseFlipout(\n",
    "          NUM_CLASSES, kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.softmax)\n",
    "  ])\n",
    "\n",
    "\n",
    "  # Model compilation.\n",
    "  optimizer = tf.keras.optimizers.Adam(lr= learning_rate)\n",
    "  # We use the categorical_crossentropy loss since the MNIST dataset contains\n",
    "  # ten labels. The Keras API will then automatically add the\n",
    "  # Kullback-Leibler divergence (contained on the individual layers of\n",
    "  # the model), to the cross entropy loss, effectively\n",
    "  # calcuating the (negated) Evidence Lower Bound Loss (ELBO)\n",
    "  model.compile(optimizer, loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'], experimental_run_tf_function=False)\n",
    "  return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "class MNISTSequence(tf.keras.utils.Sequence):\n",
    "  \"\"\"Produces a sequence of MNIST digits with labels.\"\"\"\n",
    "\n",
    "  def __init__(self, data=None, batch_size=128, fake_data_size=None):\n",
    "    \"\"\"Initializes the sequence.\n",
    "\n",
    "    Args:\n",
    "      data: Tuple of numpy `array` instances, the first representing images and\n",
    "            the second labels.\n",
    "      batch_size: Integer, number of elements in each training batch.\n",
    "      fake_data_size: Optional integer number of fake datapoints to generate.\n",
    "    \"\"\"\n",
    "    if data:\n",
    "      images, labels = data\n",
    "    else:\n",
    "      images, labels = MNISTSequence.__generate_fake_data(\n",
    "          num_images=fake_data_size, num_classes=NUM_CLASSES)\n",
    "    self.images, self.labels = MNISTSequence.__preprocessing(\n",
    "        images, labels)\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "  @staticmethod\n",
    "  def __generate_fake_data(num_images, num_classes):\n",
    "    \"\"\"Generates fake data in the shape of the MNIST dataset for unittest.\n",
    "\n",
    "    Args:\n",
    "      num_images: Integer, the number of fake images to be generated.\n",
    "      num_classes: Integer, the number of classes to be generate.\n",
    "    Returns:\n",
    "      images: Numpy `array` representing the fake image data. The\n",
    "              shape of the array will be (num_images, 28, 28).\n",
    "      labels: Numpy `array` of integers, where each entry will be\n",
    "              assigned a unique integer.\n",
    "    \"\"\"\n",
    "    images = np.random.randint(low=0, high=256,\n",
    "                               size=(num_images, IMAGE_SHAPE[0],\n",
    "                                     IMAGE_SHAPE[1]))\n",
    "    labels = np.random.randint(low=0, high=num_classes,\n",
    "                               size=num_images)\n",
    "    return images, labels\n",
    "\n",
    "  @staticmethod\n",
    "  def __preprocessing(images, labels):\n",
    "    \"\"\"Preprocesses image and labels data.\n",
    "\n",
    "    Args:\n",
    "      images: Numpy `array` representing the image data.\n",
    "      labels: Numpy `array` representing the labels data (range 0-9).\n",
    "\n",
    "    Returns:\n",
    "      images: Numpy `array` representing the image data, normalized\n",
    "              and expanded for convolutional network input.\n",
    "      labels: Numpy `array` representing the labels data (range 0-9),\n",
    "              as one-hot (categorical) values.\n",
    "    \"\"\"\n",
    "    images = 2 * (images / 255.) - 1.\n",
    "    images = images[..., tf.newaxis]\n",
    "\n",
    "    labels = tf.keras.utils.to_categorical(labels)\n",
    "    return images, labels\n",
    "\n",
    "  def __len__(self):\n",
    "    return int(tf.math.ceil(len(self.images) / self.batch_size))\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    batch_x = self.images[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "    batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "    return batch_x, batch_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "  if tf.io.gfile.exists(model_dir):\n",
    "    tf.compat.v1.logging.warning(\n",
    "        'Warning: deleting old log directory at {}'.format(model_dir))\n",
    "    tf.io.gfile.rmtree(model_dir)\n",
    "  tf.io.gfile.makedirs(model_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "1    6742\n7    6265\n3    6131\n2    5958\n9    5949\n0    5923\n6    5918\n8    5851\n4    5842\n5    5421\ndtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, heldout_set = tf.keras.datasets.mnist.load_data()\n",
    "import pandas as pd\n",
    "labels = pd.Series(train_set[1])\n",
    "labels.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([    0,     1,     2, ..., 59997, 59998, 59999], dtype=int64),)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where_out = np.where(train_set[1] == 3)\n",
    "where_out\n",
    "where_in = np.where(train_set[1] != 3)\n",
    "where_in"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(6131, 28, 28)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_out = train_set[0][where_out]\n",
    "train_set_out = (train_set[0][where_out], train_set[1][where_out])\n",
    "train_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(53869, 28, 28)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_in = train_set[0][where_in]\n",
    "train_set_in = (train_set[0][where_in], train_set[1][where_in])\n",
    "train_in.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 28, 28)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "1    1135\n2    1032\n7    1028\n3    1010\n9    1009\n4     982\n0     980\n8     974\n6     958\n5     892\ndtype: int64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heldout_y_srs = pd.Series(heldout_set[1])\n",
    "heldout_y_srs.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "heldout_x = heldout_set[0]\n",
    "heldout_y = heldout_set[1]\n",
    "reorder_heldout = list()\n",
    "for digit in range(10):\n",
    "    where_digit = np.where(heldout_y == digit)\n",
    "    reorder_heldout.append(where_digit[0][0])\n",
    "reorder_heldout.extend(list(range(len(heldout_x))))\n",
    "heldout_x = heldout_x[reorder_heldout]\n",
    "heldout_y = heldout_y[reorder_heldout]\n",
    "heldout_set = (heldout_x, heldout_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train_seq = MNISTSequence(data=train_set_in, batch_size=batch_size)\n",
    "heldout_seq = MNISTSequence(data=heldout_set, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.build(input_shape=[None, 28, 28, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... Training convolutional neural network\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "# num_epochs = 300\n",
    "# print(' ... Training convolutional neural network')\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(epoch)\n",
    "#     epoch_accuracy, epoch_loss = [], []\n",
    "#     for step, (batch_x, batch_y) in enumerate(train_seq):\n",
    "#       batch_loss, batch_accuracy = model.train_on_batch(\n",
    "#           batch_x, batch_y)\n",
    "#       # epoch_accuracy.append(batch_accuracy)\n",
    "#       # epoch_loss.append(batch_loss)\n",
    "#       #\n",
    "#       # if step % 100 == 0:\n",
    "#       #   print('Epoch: {}, Batch index: {}, '\n",
    "#       #         'Loss: {:.3f}, Accuracy: {:.3f}'.format(\n",
    "#       #             epoch, step,\n",
    "#       #             tf.reduce_mean(epoch_loss),\n",
    "#       #             tf.reduce_mean(epoch_accuracy)))\n",
    "#       #\n",
    "#       # if (step+1) % viz_steps == 0:\n",
    "#       #   # Compute log prob of heldout set by averaging draws from the model:\n",
    "#       #   # p(heldout | train) = int_model p(heldout|model) p(model|train)\n",
    "#       #   #                   ~= 1/n * sum_{i=1}^n p(heldout | model_i)\n",
    "#       #   # where model_i is a draw from the posterior p(model|train).\n",
    "#       #   print(' ... Running monte carlo inference')\n",
    "#       #   probs = tf.stack([model.predict(heldout_seq, verbose=1)\n",
    "#       #                     for _ in range(num_monte_carlo)], axis=0)\n",
    "#       #   mean_probs = tf.reduce_mean(probs, axis=0)\n",
    "#       #   heldout_log_prob = tf.reduce_mean(tf.math.log(mean_probs))\n",
    "#       #   print(' ... Held-out nats: {:.3f}'.format(heldout_log_prob))\n",
    "#       #\n",
    "#       #   if HAS_SEABORN:\n",
    "#       #     names = [layer.name for layer in model.layers\n",
    "#       #              if 'flipout' in layer.name]\n",
    "#       #     qm_vals = [layer.kernel_posterior.mean().numpy()\n",
    "#       #                for layer in model.layers\n",
    "#       #                if 'flipout' in layer.name]\n",
    "#       #     qs_vals = [layer.kernel_posterior.stddev().numpy()\n",
    "#       #                for layer in model.layers\n",
    "#       #                if 'flipout' in layer.name]\n",
    "#       #     plot_weight_posteriors(names, qm_vals, qs_vals,\n",
    "#       #                            fname=os.path.join(\n",
    "#       #                                model_dir,\n",
    "#       #                                'epoch{}_step{:05d}_weights.png'.format(\n",
    "#       #                                    epoch, step)))\n",
    "#       #     plot_heldout_prediction(heldout_seq.images, probs.numpy(),\n",
    "#       #                             fname=os.path.join(\n",
    "#       #                                 model_dir,\n",
    "#       #                                 'epoch{}_step{}_pred.png'.format(\n",
    "#       #                                     epoch, step)),\n",
    "#       #                             title='mean heldout logprob {:.2f}'\n",
    "#       #                             .format(heldout_log_prob))\n",
    "# model.save('mnist_bayes.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 5s 40ms/step\n",
      "79/79 [==============================] - 3s 41ms/step\n",
      "79/79 [==============================] - 3s 40ms/step\n",
      "79/79 [==============================] - 3s 41ms/step\n",
      "79/79 [==============================] - 4s 47ms/step\n",
      "saved final_bayes\\pred.png\n"
     ]
    }
   ],
   "source": [
    "num_monte_carlo = 5\n",
    "\n",
    "probs = tf.stack([model.predict(heldout_seq, verbose=1)\n",
    "                  for _ in range(num_monte_carlo)], axis=0)\n",
    "mean_probs = tf.reduce_mean(probs, axis=0)\n",
    "heldout_log_prob = tf.reduce_mean(tf.math.log(mean_probs))\n",
    "\n",
    "model_dir = 'final_bayes'\n",
    "plot_heldout_prediction(heldout_seq.images, probs.numpy(),\n",
    "                                  fname=os.path.join(\n",
    "                                      model_dir,\n",
    "                                      'pred.png'.format(\n",
    "                                          epoch, step)),\n",
    "                                  title='mean heldout logprob {:.2f}'\n",
    "                                  .format(heldout_log_prob))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "heldout_x = heldout_set[0]\n",
    "heldout_y = heldout_set[1]\n",
    "reorder_heldout = list()\n",
    "\n",
    "where_digit = np.where(heldout_y == 3)[0].tolist()\n",
    "\n",
    "heldout_x = heldout_x[where_digit]\n",
    "heldout_y = heldout_y[where_digit]\n",
    "heldout_set = (heldout_x, heldout_y)\n",
    "heldout_seq = MNISTSequence(data=heldout_set, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "where_digit = np.where(heldout_y == 3)[0].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 80ms/step\n",
      "8/8 [==============================] - 0s 47ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 42ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 43ms/step\n",
      "8/8 [==============================] - 0s 42ms/step\n",
      "8/8 [==============================] - 0s 42ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 39ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 58ms/step\n",
      "8/8 [==============================] - 1s 82ms/step\n",
      "8/8 [==============================] - 1s 71ms/step\n",
      "8/8 [==============================] - 0s 53ms/step\n",
      "8/8 [==============================] - 1s 68ms/step\n",
      "8/8 [==============================] - 1s 67ms/step\n",
      "8/8 [==============================] - 1s 56ms/step\n",
      "8/8 [==============================] - 1s 75ms/step\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 42ms/step\n",
      "8/8 [==============================] - 0s 48ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "8/8 [==============================] - 0s 60ms/step\n",
      "8/8 [==============================] - 0s 42ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 43ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 42ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 42ms/step\n",
      "8/8 [==============================] - 0s 40ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 42ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "saved final_bayes\\pred_0.png\n",
      "saved final_bayes\\pred_1.png\n",
      "saved final_bayes\\pred_2.png\n",
      "saved final_bayes\\pred_3.png\n",
      "saved final_bayes\\pred_4.png\n"
     ]
    }
   ],
   "source": [
    "num_monte_carlo = 100\n",
    "\n",
    "probs = tf.stack([model.predict(heldout_seq, verbose=1)\n",
    "                  for _ in range(num_monte_carlo)], axis=0)\n",
    "mean_probs = tf.reduce_mean(probs, axis=0)\n",
    "heldout_log_prob = tf.reduce_mean(tf.math.log(mean_probs))\n",
    "for i in range(5):\n",
    "    plot_heldout_prediction(heldout_seq.images[10*i:10*i+10], probs.numpy()[:,10*i:10*i+10,:],\n",
    "                                      fname=os.path.join(\n",
    "                                          model_dir,\n",
    "                                          f'pred_{i}.png'.format(\n",
    "                                              epoch, step)),\n",
    "                                      title='mean heldout logprob {:.2f}'\n",
    "                                      .format(heldout_log_prob))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "probs_np = probs.numpy()\n",
    "probs_np = probs_np[:,10*i:10*i+10,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 46ms/step\n",
      "8/8 [==============================] - 0s 43ms/step\n",
      "8/8 [==============================] - 0s 42ms/step\n",
      "8/8 [==============================] - 0s 42ms/step\n",
      "8/8 [==============================] - 0s 42ms/step\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 42ms/step\n",
      "8/8 [==============================] - 0s 43ms/step\n",
      "8/8 [==============================] - 0s 42ms/step\n",
      "8/8 [==============================] - 0s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "num_monte_carlo = 10\n",
    "probs = tf.stack([model.predict(heldout_seq, verbose=1)\n",
    "                  for _ in range(num_monte_carlo)], axis=0).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "images = heldout_seq.images\n",
    "labels = heldout_seq.labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "true_labels = list()\n",
    "pred_labels = list()\n",
    "for i in range(len(images)):\n",
    "    true_label = np.argmax(labels[i])\n",
    "    pred_means = np.mean(probs[:, i, :], axis=0)\n",
    "    pred_label = np.argmax(pred_means)\n",
    "    if pred_means[pred_label] > 0.95:\n",
    "        true_labels.append(true_label)\n",
    "        pred_labels.append(pred_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "0.3125618199802176"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_labels)/len(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}