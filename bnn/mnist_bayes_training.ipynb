{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import figure\n",
    "from matplotlib.backends import backend_agg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "warnings.simplefilter(action='ignore')\n",
    "import seaborn as sns\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = [28, 28, 1]\n",
    "NUM_TRAIN_EXAMPLES = 60000\n",
    "NUM_HELDOUT_EXAMPLES = 10000\n",
    "NUM_CLASSES = 10\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 300\n",
    "BATCH_SIZE =128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  kl_divergence_function = (lambda q, p, _: tfd.kl_divergence(q, p) / tf.cast(NUM_TRAIN_EXAMPLES, dtype=tf.float32))\n",
    "\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tfp.layers.Convolution2DFlipout(\n",
    "          6, kernel_size=5, padding='SAME',\n",
    "          kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.relu),\n",
    "      tf.keras.layers.MaxPooling2D(\n",
    "          pool_size=[2, 2], strides=[2, 2],\n",
    "          padding='SAME'),\n",
    "      tfp.layers.Convolution2DFlipout(\n",
    "          16, kernel_size=5, padding='SAME',\n",
    "          kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.relu),\n",
    "      tf.keras.layers.MaxPooling2D(\n",
    "          pool_size=[2, 2], strides=[2, 2],\n",
    "          padding='SAME'),\n",
    "      tfp.layers.Convolution2DFlipout(\n",
    "          120, kernel_size=5, padding='SAME',\n",
    "          kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.relu),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tfp.layers.DenseFlipout(\n",
    "          84, kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.relu),\n",
    "      tfp.layers.DenseFlipout(\n",
    "          NUM_CLASSES, kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.softmax)\n",
    "  ])\n",
    "\n",
    "  model.compile(tf.keras.optimizers.Adam(lr= LEARNING_RATE),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'],\n",
    "                experimental_run_tf_function=False)\n",
    "  return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class DatasetSequence(tf.keras.utils.Sequence):\n",
    "\n",
    "  def __init__(self, data, batch_size=128):\n",
    "    images, labels = data\n",
    "    self.images, self.labels = DatasetSequence.__preprocessing(images, labels)\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "  @staticmethod\n",
    "  def __preprocessing(images, labels):\n",
    "    images = 2 * (images / 255.) - 1.\n",
    "    images = images[..., tf.newaxis]\n",
    "    labels = tf.keras.utils.to_categorical(labels)\n",
    "    return images, labels\n",
    "\n",
    "  def __len__(self):\n",
    "    return int(tf.math.ceil(len(self.images) / self.batch_size))\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    batch_x = self.images[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "    batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "    return batch_x, batch_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class count\n"
     ]
    },
    {
     "data": {
      "text/plain": "1    6742\n7    6265\n3    6131\n2    5958\n9    5949\n0    5923\n6    5918\n8    5851\n4    5842\n5    5421\ndtype: int64"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, heldout_set = tf.keras.datasets.mnist.load_data()\n",
    "labels = pd.Series(train_set[1])\n",
    "print(\"Training set class count\")\n",
    "labels.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([    0,     1,     2, ..., 59997, 59998, 59999], dtype=int64),)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where_out = np.where(train_set[1] == 3)\n",
    "where_out\n",
    "where_in = np.where(train_set[1] != 3)\n",
    "where_in"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(6131, 28, 28)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_out = train_set[0][where_out]\n",
    "train_set_out = (train_set[0][where_out], train_set[1][where_out])\n",
    "train_out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "(53869, 28, 28)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_in = train_set[0][where_in]\n",
    "train_set_in = (train_set[0][where_in], train_set[1][where_in])\n",
    "train_in.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 28, 28)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "1    1135\n2    1032\n7    1028\n3    1010\n9    1009\n4     982\n0     980\n8     974\n6     958\n5     892\ndtype: int64"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heldout_y_srs = pd.Series(heldout_set[1])\n",
    "heldout_y_srs.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "heldout_x = heldout_set[0]\n",
    "heldout_y = heldout_set[1]\n",
    "reorder_heldout = list()\n",
    "for digit in range(10):\n",
    "    where_digit = np.where(heldout_y == digit)\n",
    "    reorder_heldout.append(where_digit[0][0])\n",
    "reorder_heldout.extend(list(range(len(heldout_x))))\n",
    "heldout_x = heldout_x[reorder_heldout]\n",
    "heldout_y = heldout_y[reorder_heldout]\n",
    "heldout_set = (heldout_x, heldout_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "train_seq = DatasetSequence(data=train_set_in, batch_size=BATCH_SIZE)\n",
    "heldout_seq = DatasetSequence(data=heldout_set, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.build(input_shape=[None, 28, 28, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... Training convolutional neural network\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "INFO:tensorflow:Assets written to: mnist_bayes.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "print(' ... Training convolutional neural network')\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(epoch)\n",
    "    epoch_accuracy, epoch_loss = [], []\n",
    "    for step, (batch_x, batch_y) in enumerate(train_seq):\n",
    "      batch_loss, batch_accuracy = model.train_on_batch(batch_x, batch_y)\n",
    "      print(step)\n",
    "      # epoch_accuracy.append(batch_accuracy)\n",
    "      # epoch_loss.append(batch_loss)\n",
    "      #\n",
    "      # if step % 100 == 0:\n",
    "      #   print('Epoch: {}, Batch index: {}, '\n",
    "      #         'Loss: {:.3f}, Accuracy: {:.3f}'.format(\n",
    "      #             epoch, step,\n",
    "      #             tf.reduce_mean(epoch_loss),\n",
    "      #             tf.reduce_mean(epoch_accuracy)))\n",
    "      #\n",
    "      # if (step+1) % viz_steps == 0:\n",
    "      #   # Compute log prob of heldout set by averaging draws from the model:\n",
    "      #   # p(heldout | train) = int_model p(heldout|model) p(model|train)\n",
    "      #   #                   ~= 1/n * sum_{i=1}^n p(heldout | model_i)\n",
    "      #   # where model_i is a draw from the posterior p(model|train).\n",
    "      #   print(' ... Running monte carlo inference')\n",
    "      #   probs = tf.stack([model.predict(heldout_seq, verbose=1)\n",
    "      #                     for _ in range(num_monte_carlo)], axis=0)\n",
    "      #   mean_probs = tf.reduce_mean(probs, axis=0)\n",
    "      #   heldout_log_prob = tf.reduce_mean(tf.math.log(mean_probs))\n",
    "      #   print(' ... Held-out nats: {:.3f}'.format(heldout_log_prob))\n",
    "      #\n",
    "      #   if HAS_SEABORN:\n",
    "      #     names = [layer.name for layer in model.layers\n",
    "      #              if 'flipout' in layer.name]\n",
    "      #     qm_vals = [layer.kernel_posterior.mean().numpy()\n",
    "      #                for layer in model.layers\n",
    "      #                if 'flipout' in layer.name]\n",
    "      #     qs_vals = [layer.kernel_posterior.stddev().numpy()\n",
    "      #                for layer in model.layers\n",
    "      #                if 'flipout' in layer.name]\n",
    "      #     plot_weight_posteriors(names, qm_vals, qs_vals,\n",
    "      #                            fname=os.path.join(\n",
    "      #                                model_dir,\n",
    "      #                                'epoch{}_step{:05d}_weights.png'.format(\n",
    "      #                                    epoch, step)))\n",
    "      #     plot_heldout_prediction(heldout_seq.images, probs.numpy(),\n",
    "      #                             fname=os.path.join(\n",
    "      #                                 model_dir,\n",
    "      #                                 'epoch{}_step{}_pred.png'.format(\n",
    "      #                                     epoch, step)),\n",
    "      #                             title='mean heldout logprob {:.2f}'\n",
    "      #                             .format(heldout_log_prob))\n",
    "model.save('mnist_bayes.tf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 240ms/step\n",
      "11/11 [==============================] - 3s 245ms/step\n",
      "11/11 [==============================] - 3s 279ms/step\n",
      "11/11 [==============================] - 3s 241ms/step\n",
      "11/11 [==============================] - 3s 284ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('mnist_bayes.tf')\n",
    "num_monte_carlo = 5\n",
    "\n",
    "probs = tf.stack([model.predict(heldout_seq, verbose=1)\n",
    "                  for _ in range(num_monte_carlo)], axis=0)\n",
    "mean_probs = tf.reduce_mean(probs, axis=0)\n",
    "heldout_log_prob = tf.reduce_mean(tf.math.log(mean_probs))\n",
    "\n",
    "model_dir = 'final_bayes'\n",
    "# plot_heldout_prediction(heldout_seq.images, probs.numpy(),\n",
    "#                                   fname=os.path.join(\n",
    "#                                       model_dir,\n",
    "#                                       'pred.png'.format(\n",
    "#                                           epoch, step)),\n",
    "#                                   title='mean heldout logprob {:.2f}'\n",
    "#                                   .format(heldout_log_prob))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "heldout_x = heldout_set[0]\n",
    "heldout_y = heldout_set[1]\n",
    "reorder_heldout = list()\n",
    "\n",
    "where_digit = np.where(heldout_y == 3)[0].tolist()\n",
    "\n",
    "heldout_x = heldout_x[where_digit]\n",
    "heldout_y = heldout_y[where_digit]\n",
    "heldout_set = (heldout_x, heldout_y)\n",
    "heldout_seq = DatasetSequence(data=heldout_set, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "where_digit = np.where(heldout_y == 3)[0].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_monte_carlo = 100\n",
    "\n",
    "probs = tf.stack([model.predict(heldout_seq, verbose=1)\n",
    "                  for _ in range(num_monte_carlo)], axis=0)\n",
    "mean_probs = tf.reduce_mean(probs, axis=0)\n",
    "heldout_log_prob = tf.reduce_mean(tf.math.log(mean_probs))\n",
    "for i in range(5):\n",
    "    plot_heldout_prediction(heldout_seq.images[10*i:10*i+10], probs.numpy()[:,10*i:10*i+10,:],\n",
    "                                      fname=os.path.join(\n",
    "                                          model_dir,\n",
    "                                          f'pred_{i}.png'.format(\n",
    "                                              epoch, step)),\n",
    "                                      title='mean heldout logprob {:.2f}'\n",
    "                                      .format(heldout_log_prob))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probs_np = probs.numpy()\n",
    "probs_np = probs_np[:,10*i:10*i+10,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_monte_carlo = 10\n",
    "probs = tf.stack([model.predict(heldout_seq, verbose=1)\n",
    "                  for _ in range(num_monte_carlo)], axis=0).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images = heldout_seq.images\n",
    "labels = heldout_seq.labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_labels = list()\n",
    "pred_labels = list()\n",
    "for i in range(len(images)):\n",
    "    true_label = np.argmax(labels[i])\n",
    "    pred_means = np.mean(probs[:, i, :], axis=0)\n",
    "    pred_label = np.argmax(pred_means)\n",
    "    if pred_means[pred_label] > 0.95:\n",
    "        true_labels.append(true_label)\n",
    "        pred_labels.append(pred_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(pred_labels)/len(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}